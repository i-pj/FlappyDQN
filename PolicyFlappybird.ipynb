{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flappy-bird-gymnasium\n",
        "!pip install gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy1ZJ8qvrNR7",
        "outputId": "8b1e54d0-e878-4082-a1b4-ee8c349e3766"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flappy-bird-gymnasium\n",
            "  Downloading flappy_bird_gymnasium-0.4.0-py3-none-any.whl (37.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium (from flappy-bird-gymnasium)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (1.25.2)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (2.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (3.7.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium->flappy-bird-gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->flappy-bird-gymnasium) (1.16.0)\n",
            "Installing collected packages: farama-notifications, gymnasium, flappy-bird-gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 flappy-bird-gymnasium-0.4.0 gymnasium-0.29.1\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "# Gym\n",
        "import flappy_bird_gymnasium\n",
        "import gymnasium as gym\n",
        "\n"
      ],
      "metadata": {
        "id": "sYysLOMWrYQm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = 'FlappyBird-v0'\n",
        "env = gym.make(env_id, render_mode=\"human\", use_lidar=True)\n",
        "\n",
        "# evaluation env\n",
        "eval_env = gym.make(env_id, render_mode=\"human\", use_lidar=True)\n",
        "\n",
        "# state space and action space\n",
        "s_size = env.observation_space.shape[0]\n",
        "a_size = env.action_space.n"
      ],
      "metadata": {
        "id": "MVQ5EyiwtzaT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(s_size)\n",
        "print(a_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-VMb4HKuFRu",
        "outputId": "31fa588e-3ab9-4fd8-ca6f-be277ee3cd60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Policy(nn.Module):\n",
        "    def __init__(self, s_size, a_size, h_size):\n",
        "        super(Policy, self).__init__()\n",
        "        self.fc1 = nn.Linear(s_size, h_size)\n",
        "        self.fc2 = nn.Linear(h_size, h_size*2)\n",
        "        self.fc3 = nn.Linear(h_size*2, a_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "    def act(self, state):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        probs = self.forward(state).cpu()\n",
        "        m = Categorical(probs)\n",
        "        action = m.sample()\n",
        "        return action.item(), m.log_prob(action)"
      ],
      "metadata": {
        "id": "NhB3jPmEvDWM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reinforce(policy, optimizer, n_training_episodes, max_t, gamma, print_every):\n",
        "\n",
        "    scores_deque = deque(maxlen=100)\n",
        "    scores = []\n",
        "\n",
        "    for i_episode in range(1, n_training_episodes+1):\n",
        "        saved_log_probs = []\n",
        "        rewards = []\n",
        "        state = env.reset()[0]\n",
        "\n",
        "        for t in range(max_t):\n",
        "            action, log_prob = policy.act(state)\n",
        "            saved_log_probs.append(log_prob)\n",
        "            state, reward, done, info, _ = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            if done:\n",
        "                break\n",
        "        scores_deque.append(sum(rewards))\n",
        "        scores.append(sum(rewards))\n",
        "\n",
        "        returns = deque(maxlen=max_t)\n",
        "        n_steps = len(rewards)\n",
        "\n",
        "        for t in range(n_steps)[::-1]:\n",
        "            disc_return_t = (returns[0] if len(returns)>0 else 0)\n",
        "            returns.appendleft( gamma*disc_return_t + rewards[t]   )\n",
        "\n",
        "        eps = np.finfo(np.float32).eps.item()\n",
        "\n",
        "        returns = torch.tensor(returns)\n",
        "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
        "\n",
        "        policy_loss = []\n",
        "        for log_prob, disc_return in zip(saved_log_probs, returns):\n",
        "            policy_loss.append(-log_prob * disc_return)\n",
        "        policy_loss = torch.cat(policy_loss).sum()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i_episode % print_every == 0:\n",
        "            print('Episode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "fYMsU_YivM3C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejoAniXfwxLK",
        "outputId": "51cd3f2c-d4cc-4952-af0e-a4f98b16ed3d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flappybird_hyperparameters = {\n",
        "    \"h_size\": 64,\n",
        "    \"n_training_episodes\": 50000,\n",
        "    \"n_evaluation_episodes\": 10,\n",
        "    \"max_t\": 10000,\n",
        "    \"gamma\": 0.99,\n",
        "    \"lr\": 1e-4,\n",
        "    \"env_id\": env_id,\n",
        "    \"state_space\": s_size,\n",
        "    \"action_space\": a_size,\n",
        "}"
      ],
      "metadata": {
        "id": "yNyX-1nHvhGn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flappybird_policy = Policy(flappybird_hyperparameters[\"state_space\"], flappybird_hyperparameters[\"action_space\"], flappybird_hyperparameters[\"h_size\"]).to(device)\n",
        "flappybird_optimizer = optim.Adam(flappybird_policy.parameters(), lr=flappybird_hyperparameters[\"lr\"])"
      ],
      "metadata": {
        "id": "7NYF2d18vkuW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = reinforce(flappybird_policy,\n",
        "                   flappybird_optimizer,\n",
        "                   flappybird_hyperparameters[\"n_training_episodes\"],\n",
        "                   flappybird_hyperparameters[\"max_t\"],\n",
        "                   flappybird_hyperparameters[\"gamma\"],\n",
        "                   100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JccEUwpewi3i",
        "outputId": "3319bc9e-015b-402d-949b-16ea6e5d6acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100\tAverage Score: -7.20\n",
            "Episode 200\tAverage Score: -6.58\n",
            "Episode 300\tAverage Score: -3.26\n",
            "Episode 400\tAverage Score: -0.59\n",
            "Episode 500\tAverage Score: -0.14\n",
            "Episode 600\tAverage Score: -0.45\n",
            "Episode 700\tAverage Score: -0.41\n",
            "Episode 800\tAverage Score: -0.26\n",
            "Episode 900\tAverage Score: -0.34\n",
            "Episode 1000\tAverage Score: -0.46\n",
            "Episode 1100\tAverage Score: -0.37\n",
            "Episode 1200\tAverage Score: -0.05\n",
            "Episode 1300\tAverage Score: -0.11\n",
            "Episode 1400\tAverage Score: -0.49\n",
            "Episode 1500\tAverage Score: -0.13\n",
            "Episode 1600\tAverage Score: -0.66\n",
            "Episode 1700\tAverage Score: -0.60\n",
            "Episode 1800\tAverage Score: -0.24\n",
            "Episode 1900\tAverage Score: -0.19\n",
            "Episode 2000\tAverage Score: -0.37\n",
            "Episode 2100\tAverage Score: -0.26\n",
            "Episode 2200\tAverage Score: -0.24\n",
            "Episode 2300\tAverage Score: -0.13\n",
            "Episode 2400\tAverage Score: -0.28\n",
            "Episode 2500\tAverage Score: -0.19\n",
            "Episode 2600\tAverage Score: 0.06\n",
            "Episode 2700\tAverage Score: -0.32\n",
            "Episode 2800\tAverage Score: -0.31\n",
            "Episode 2900\tAverage Score: -0.09\n",
            "Episode 3000\tAverage Score: -0.32\n",
            "Episode 3100\tAverage Score: -0.09\n",
            "Episode 3200\tAverage Score: -0.69\n",
            "Episode 3300\tAverage Score: -0.11\n",
            "Episode 3400\tAverage Score: 0.29\n",
            "Episode 3500\tAverage Score: 0.12\n",
            "Episode 3600\tAverage Score: -0.32\n",
            "Episode 3700\tAverage Score: 0.30\n",
            "Episode 3800\tAverage Score: -0.15\n",
            "Episode 3900\tAverage Score: 0.32\n",
            "Episode 4000\tAverage Score: 0.00\n",
            "Episode 4100\tAverage Score: -0.15\n",
            "Episode 4200\tAverage Score: -0.24\n",
            "Episode 4300\tAverage Score: 0.05\n",
            "Episode 4400\tAverage Score: 0.82\n",
            "Episode 4500\tAverage Score: 0.91\n",
            "Episode 4600\tAverage Score: 0.50\n",
            "Episode 4700\tAverage Score: -0.29\n",
            "Episode 4800\tAverage Score: 0.17\n",
            "Episode 4900\tAverage Score: 1.23\n",
            "Episode 5000\tAverage Score: 0.63\n",
            "Episode 5100\tAverage Score: 1.65\n",
            "Episode 5200\tAverage Score: 2.03\n",
            "Episode 5300\tAverage Score: 2.48\n",
            "Episode 5400\tAverage Score: 2.30\n",
            "Episode 5500\tAverage Score: 2.51\n",
            "Episode 5600\tAverage Score: 4.02\n",
            "Episode 5700\tAverage Score: 3.29\n",
            "Episode 5800\tAverage Score: 4.01\n",
            "Episode 5900\tAverage Score: 4.86\n",
            "Episode 6000\tAverage Score: 8.08\n",
            "Episode 6100\tAverage Score: 8.20\n",
            "Episode 6200\tAverage Score: 7.51\n",
            "Episode 6300\tAverage Score: 8.90\n",
            "Episode 6400\tAverage Score: 9.59\n",
            "Episode 6500\tAverage Score: 13.71\n",
            "Episode 6600\tAverage Score: 13.00\n",
            "Episode 6700\tAverage Score: 10.20\n",
            "Episode 6800\tAverage Score: 12.98\n",
            "Episode 6900\tAverage Score: 11.20\n",
            "Episode 7000\tAverage Score: 15.70\n",
            "Episode 7100\tAverage Score: 14.02\n",
            "Episode 7200\tAverage Score: 17.81\n",
            "Episode 7300\tAverage Score: 15.74\n",
            "Episode 7400\tAverage Score: 18.74\n",
            "Episode 7500\tAverage Score: 17.30\n",
            "Episode 7600\tAverage Score: 19.36\n",
            "Episode 7700\tAverage Score: 17.17\n",
            "Episode 7800\tAverage Score: 15.49\n",
            "Episode 7900\tAverage Score: 19.11\n",
            "Episode 8000\tAverage Score: 20.19\n",
            "Episode 8100\tAverage Score: 17.40\n",
            "Episode 8200\tAverage Score: 20.81\n",
            "Episode 8300\tAverage Score: 21.92\n",
            "Episode 8400\tAverage Score: 19.28\n",
            "Episode 8500\tAverage Score: 17.31\n",
            "Episode 8600\tAverage Score: 21.59\n",
            "Episode 8700\tAverage Score: 25.76\n",
            "Episode 8800\tAverage Score: 18.59\n",
            "Episode 8900\tAverage Score: 18.27\n",
            "Episode 9000\tAverage Score: 19.04\n",
            "Episode 9100\tAverage Score: 16.76\n",
            "Episode 9200\tAverage Score: 23.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(policy.state_dict(), 'policy.pth')"
      ],
      "metadata": {
        "id": "8Z7F85xaxJTo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "46900d8b-e30a-4b05-e21b-36fff71d5bc6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'policy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-684302aabcb6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'policy.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'policy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dizpx9cM-USK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}